<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Benjamin Guinebertière&#39;s blog (@benjguin)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Benjamin Guinebertière's blog (@benjguin)">
<meta property="og:url" content="http://blog.3-4.fr/index.html">
<meta property="og:site_name" content="Benjamin Guinebertière's blog (@benjguin)">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Benjamin Guinebertière's blog (@benjguin)">
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  <script type='text/javascript' src='/js/tag.js'></script>
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Benjamin Guinebertière&#39;s blog (@benjguin)</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://blog.3-4.fr"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2015/12/02/mapr-on-azure" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/12/02/mapr-on-azure/" class="article-date">
  <time datetime="2015-12-01T23:00:00.000Z" itemprop="datePublished">2015-12-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/02/mapr-on-azure/">MapR on Azure</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>There are different ways to install Hadoop on Azure. The blog post about the <a href="/2015/12/02a/different-flavors-of-hadoop.html">different flavors of Hadoop</a> will provide more context.</p>
<p>This blog post shows the main steps to start with MapR on Azure. </p>
<h2 id="How-to"><a href="#How-to" class="headerlink" title="How to"></a>How to</h2><p>In order to install the cluster, follow the wizzard that you’ll find in <a href="https://portal.azure.com" target="_blank" rel="external">Azure portal</a>.</p>
<p>Here is a quick view of this wizzard: </p>
<p><img src="/images/151202b/1.png" alt=""></p>
<p><img src="/images/151202b/2.png" alt=""></p>
<p><img src="/images/151202b/3.png" alt=""></p>
<p><img src="/images/151202b/4.png" alt=""></p>
<p><img src="/images/151202b/4b.png" alt=""></p>
<p>Step 3 gives you a chance to download the generated Azure resource manager wizzard that you can modify and deploy as described in the following article: <a href="https://azure.microsoft.com/en-us/documentation/articles/resource-group-template-deploy/" target="_blank" rel="external">Deploy an application with Azure Resource Manager template</a>.</p>
<p><img src="/images/151202b/5.png" alt=""></p>
<p>Once you’ve created the cluster, go to <code>https://{yourclustername}-node0.{install-location}.cloudapp.azure.com:9443</code> and connect.</p>
<p>In my case, I named the cluster <code>mapr34</code> and installed it in North Europe region, so it is <code>https://mapr34-node0.northeurope.cloudapp.azure.com:9443</code>.</p>
<p>NB: this <code>mapr34-node0.northeurope.cloudapp.azure.com</code>host name can be found in the portal when you browse the resource group where the cluster is. It’s attached to the public IP of the node.</p>
<p><img src="/images/151202b/6.png" alt=""></p>
<p>Use mapr as the username and the password you provided in step 2 of the wizzard as the password.</p>
<p><img src="/images/151202b/7.png" alt=""></p>
<p>Select each node and check the disks where you want to install the distributed file system.<br>/dev/sdb1 is the cache disk. The 1023 GB disks are VHDs.</p>
<p>Use the Next button to move on </p>
<p><img src="/images/151202b/8.png" alt=""></p>
<p>Click <code>Install -&gt;</code> to start the installation process.</p>
<p><img src="/images/151202b/9.png" alt=""></p>
<p><img src="/images/151202b/10.png" alt=""></p>
<p>After a number of minutes, the installation completes. </p>
<p><img src="/images/151202b/11.png" alt=""></p>
<p><img src="/images/151202b/12.png" alt=""></p>
<p>On the final step, you can find a link to a short name. Unless you’ve created an SSH tunnel to your cluster, you may need to use the long name instead. In this example where my cluster is called <code>mapr34</code> and is installed in North Europe, the URL is <code>https://mapr34node1:8443/</code>. I replace it by <code>https://mapr34-node1.northeurope.cloudapp.azure.com:8443</code>. </p>
<p>NB: this <code>mapr34-node1.northeurope.cloudapp.azure.com</code>host name can be found in the portal when you browse the resource group where the cluster is. It’s attached to the public IP of the node. </p>
<p><img src="/images/151202b/13.png" alt=""></p>
<p>ypou connect with the same credentials as before: mapr/{the password you provided in step 2 of the creation wizzard}.</p>
<p><img src="/images/151202b/14.png" alt=""></p>
<p>Now that the MapR file system is installed. Let’s see it as HDFS. Let’s also check if we can access Azure blob storage.</p>
<p><img src="/images/151202b/15.png" alt=""></p>
<p>The <code>wasb</code> driver (wasb stands for Windows Azure Storage Blob) is not installed by default :-( .  </p>
<p><img src="/images/151202b/16.png" alt=""></p>
<p><img src="/images/151202b/17.png" alt=""></p>
<p>If you go back to the installation page you’ll have the option to install additional services: </p>
<p><img src="/images/151202b/18.png" alt=""></p>
<p>When you’re done, you can stop the services, before shutting down the Azure virtual machines. If there are many nodes, you may want to use Azure PowerShell module or Azure Command Line Interface (Azure CLI). You can find them in the resources section of <a href="http://azure.com" target="_blank" rel="external">azure.com</a>. </p>
<p><img src="/images/151202b/19.png" alt=""></p>
<p>You may also prefer to remove all the resources that consitute the cluster: VMs, storage, vNet and so on. Of course, all the data will be removed as well, so you are asked to type the resource group before deleting it.</p>
<p><img src="/images/151202b/20.png" alt=""></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>We saw how to create a MapR cluster in Azure. You just have to enter a few parameters in friendly Web interfaces and wait for the cloud and MapR to create everything for you!</p>
<p>:-)<br>Benjamin (<a href="http://twitter.com/@benjguin" target="_blank" rel="external">@benjguin</a>)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.3-4.fr/2015/12/02/mapr-on-azure/" data-id="ciqaupb9c0000b0cdvbwlc2sb" class="article-share-link">Share</a>
      
        <a href="http://blog.3-4.fr/2015/12/02/mapr-on-azure/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Azure/">Azure</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Big-Data/">Big Data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/12/02/different-flavors-of-hadoop" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/12/02/different-flavors-of-hadoop/" class="article-date">
  <time datetime="2015-12-01T23:00:00.000Z" itemprop="datePublished">2015-12-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/12/02/different-flavors-of-hadoop/">Different Flavors of Hadoop &amp; Spark</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>There are four main ways to install Hadoop &amp; Spark: </p>
<ul>
<li>from Apache (<a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">http://hadoop.apache.org/releases.html</a>) </li>
<li>from Cloudera’s distribution (<a href="http://www.cloudera.com" target="_blank" rel="external">http://www.cloudera.com</a>)</li>
<li>from HortonWorks’ distribution (<a href="http://hortonworks.com" target="_blank" rel="external">http://hortonworks.com</a>)</li>
<li>from MapR’s distribution (<a href="http://mapr.com" target="_blank" rel="external">http://mapr.com</a>)</li>
</ul>
<p>This blog post shows the different options in the context of Azure.</p>
<h2 id="From-Apache-http-hadoop-apache-org-releases-html"><a href="#From-Apache-http-hadoop-apache-org-releases-html" class="headerlink" title="From Apache (http://hadoop.apache.org/releases.html)"></a>From Apache (<a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">http://hadoop.apache.org/releases.html</a>)</h2><p>This option is chosen by people who want to select the components themselves, and want to get the releases as soon as they are available.  </p>
<p>If you want that option, it’s probably because your want to have control, rather than using a cluster somebody tailored for you.<br>The recommended way to do in Azure is to use Azure Virtual Machines, virtual network, and install everything yourself.<br>For that, you may want to leverage <a href="https://azure.microsoft.com/en-us/documentation/articles/resource-group-authoring-templates/" target="_blank" rel="external">Azure Resource Manager templates</a>. A number of examples are available on <a href="https://github.com/Azure/azure-quickstart-template" target="_blank" rel="external">GitHub</a>. For instance, <a href="https://github.com/Azure/azure-quickstart-templates/tree/master/zookeeper-cluster-ubuntu-vm" target="_blank" rel="external">this one</a> deploys a Zookeeper cluster on Ubuntu VMs.</p>
<h2 id="Hadoop-architecture-on-Azure"><a href="#Hadoop-architecture-on-Azure" class="headerlink" title="Hadoop architecture on Azure"></a>Hadoop architecture on Azure</h2><p>There are several ways to deploy a Hadoop cluster on Azure, and several ways to store the data.<br>A virtual machine on Azure has </p>
<ul>
<li>local disk which is mainly used for cache (Cache disk), </li>
<li>Virtual Hard Disks (VHD) that live in the Azure storage; in particular, this is the case of the OS disk (the only exception is with web and worker roles)</li>
<li>the virtual machine can also access blob storage which is a storage service where one can put files. It is accessible thru REST API, but also thru the wasb (Windows Azure Storage Blob) driver which is available in Hadoop.</li>
</ul>
<p><img src="/images/151202a/2.png" alt=""></p>
<p>Data Lake Store is also a new way of storing big data. For now (NOV 2015) it is in preview and can be used from Data Lake Analytics and HDInsight; later on, it will also be usable from standard distributions:</p>
<p><img src="/images/151202a/3.png" alt=""></p>
<h3 id="Comparing-Cloudera-Hortonworks-and-MapR"><a href="#Comparing-Cloudera-Hortonworks-and-MapR" class="headerlink" title="Comparing Cloudera, Hortonworks and MapR"></a>Comparing Cloudera, Hortonworks and MapR</h3><p><a href="https://www.bing.com/search?q=hortonworks+and+cloudera+and+mapr" target="_blank" rel="external">Many articles</a> have been written on how the distributions compare.</p>
<p>Here is how I see them.</p>
<p><strong>Hortonworks</strong> is the closest to the Apache Hadoop distribution; All their code is Apache’s code and 100% open source. Hortonworks Data Platform (HDP) is described <a href="http://hortonworks.com/hdp/whats-new/" target="_blank" rel="external">here</a>.</p>
<p><strong>Cloudera</strong> is the mots popular; in particular, users like <a href="http://www.cloudera.com/content/www/en-us/products/apache-hadoop/impala.html" target="_blank" rel="external">Impala</a> and <a href="http://www.cloudera.com/content/www/en-us/products/cloudera-manager.html" target="_blank" rel="external">Cloudera Manager</a>. Their code is 100% open source, but not 100% Apache code (yet?). They recently decided to donate Impala and Kudu to the Apache Software Foundation.</p>
<p><strong>MapR</strong> builds a distribution for business critical production applications; they are well known for their MapR file system (MapR-FS) which can be viewed as HDFS (Hadoop Distributed File System) and NFS (Network File System), and has the reputation of being fast. Mapr-FS is proprietary. The distribution is described <a href="https://www.mapr.com/products/mapr-distribution-including-apache-hadoop" target="_blank" rel="external">here</a>.</p>
<p>Anyway, the best solution is the one you chose!</p>
<p>Here is how those distribution leverage Azure. They have different approaches.</p>
<table>
<thead>
<tr>
<th>Distribution</th>
<th>uses Cache Disk</th>
<th>uses VHD</th>
<th>uses blobs</th>
<th>prices</th>
<th>options</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloudera</td>
<td>Yes</td>
<td>Yes, premium storage only</td>
<td>for cold archive only</td>
<td>high only because Cloudera supports only high end performances</td>
<td>Cluster, single VM</td>
</tr>
<tr>
<td>Hortonworks</td>
<td>not by default (HDFS)</td>
<td>Yes (HDFS)</td>
<td>Yes</td>
<td>low to high</td>
<td>Cluster, single VM, Hadoop as a service (HDInsight)</td>
</tr>
<tr>
<td>MapR</td>
<td>Yes (Mapr-FS)</td>
<td>Yes (Mapr-FS)</td>
<td>No. wasb driver is not installed</td>
<td>low to high</td>
<td>Cluster</td>
</tr>
</tbody>
</table>
<p>NB: the options mentioned above are automated ones. Of course, you can leverage Azure virtual machines and virtual networks to install any distribution you like on a single VM or on a cluster. </p>
<p>The fact that Cloudera only supports blob storage as a cold archive makes it more difficult to create different clusters on the same storage. It also requires that you save the data to blob storage explicitely before shutting down if you need to access the data while the cluster is off.</p>
<p>With MapR, as you don’t have the wasb driver, it is difficult to make the data available while the cluster is shut down.</p>
<p>With Hortonworks, you can use Azure blob storage as the default distributed file system. With that, you can start the cluster only when you need compute power. The rest of the time, you can bring data to the storage thru REST API, or SDKs in different languages. When you need compute, you can create a cluster that has the required size. You loose collocality (which is mainly important in the first map phase, before shuffle), but you win a lot of flexibility. </p>
<p>I hope that MapR and Cloudera will enhance their usage of cloud storage with Azure Data Lake Store. Azure Data Lake should meet the performance requirements of Cloudera so that they don’t use it only for cold archive. I’m quite confident that Hortonworks will add Azure Data Lake driver. This is already the case with HDInsight. </p>
<p>Let now see how you can deploy those distributions on Azure.</p>
<h3 id="Cloudera-http-www-cloudera-com"><a href="#Cloudera-http-www-cloudera-com" class="headerlink" title="Cloudera (http://www.cloudera.com)"></a>Cloudera (<a href="http://www.cloudera.com" target="_blank" rel="external">http://www.cloudera.com</a>)</h3><p>There are different options. This <a href="http://www.cloudera.com/content/dam/cloudera/Resources/PDF/Datasheet/datasheet-cloudera-enterprise.pdf" target="_blank" rel="external">page</a> from Cloudera’s web site show the different available distributions. From Azure marketplace, you can find the following (as of 2 DEC 2015):</p>
<p><img src="/images/151202a/4.png" alt=""></p>
<p>An automated way of deploying a <strong>Cloudera Enterprise Data Hub cluster</strong> <a href="https://azure.microsoft.com/en-us/marketplace/partners/cloudera/clouderaedhcloudera/" target="_blank" rel="external">has been made available by Cloudera on Azure</a>. </p>
<p><img src="/images/151202a/1.png" alt=""></p>
<p>You’ll find a <a href="https://azure.microsoft.com/en-us/blog/full-cloudera-enterprise-edh-support-on-azure/" target="_blank" rel="external">blog post</a> on how to deploy it on the Azure web site. Also make sure to read the last paragraph (Cloudera Enterprise Deployment from GitHub) which explains there is also a <a href="https://github.com/Azure/azure-quickstart-templates/tree/master/cloudera-on-centos" target="_blank" rel="external">template on GitHub</a> if you need more flexibility.</p>
<p>If you prefer to install <strong>a single VM</strong>, you can use the Cloudera-Centos-6.6 offer. Its documentation is available at <a href="https://azure.microsoft.com/en-us/marketplace/partners/cloudera/cloudera-centos-6/" target="_blank" rel="external">azure.microsoft.com/en-us/marketplace/partners/cloudera/cloudera-centos-6/</a>.</p>
<h3 id="HortonWorks-http-hortonworks-com"><a href="#HortonWorks-http-hortonworks-com" class="headerlink" title="HortonWorks (http://hortonworks.com)"></a>HortonWorks (<a href="http://hortonworks.com" target="_blank" rel="external">http://hortonworks.com</a>)</h3><p>In order to install <strong>Hadoop as a service</strong> with an Hadoop Data Platform, you can leverage HDInsight on Windows or Linux nodes. Documentation is available at <a href="https://azure.microsoft.com/en-us/documentation/services/hdinsight/" target="_blank" rel="external">azure.microsoft.com/en-us/documentation/services/hdinsight/</a>.</p>
<p>Besides HDInsight, the marketplace has other options: </p>
<p><img src="/images/151202a/5.png" alt=""></p>
<p>In order to install an <strong>HDP cluster</strong>, you can leverage the wizzard. Note that as of today (2 DEC 2015), the wizzard deploys HDP 2.1, while latest version of HDP is 2.3. An updated version of this wizzard should be made available in the coming weeks, hopefully. If you want to have an early look at this, I think this is on Github: <a href="https://github.com/Azure/azure-quickstart-templates/tree/master/hortonworks-on-centos" target="_blank" rel="external">github.com/Azure/azure-quickstart-templates/tree/master/hortonworks-on-centos</a>.</p>
<p>If you want to install <strong>a single VM</strong>, a sandbox is available. If you can read French or if you know how to have the page translated for you, you are welcome to read my previous post: <a href="http://blogs.msdn.com/b/benjguin/archive/2015/11/16/hadoop-comment-r-233-duire-ses-co-251-ts-hdinsight-pour-le-d-233-veloppement.aspx" target="_blank" rel="external">Hadoop : Comment réduire ses coûts HDInsight pour le développement</a></p>
<h3 id="MapR-http-mapr-com"><a href="#MapR-http-mapr-com" class="headerlink" title="MapR (http://mapr.com)"></a>MapR (<a href="http://mapr.com" target="_blank" rel="external">http://mapr.com</a>)</h3><p>MapR is also available on the Azure marketplace: </p>
<p><img src="/images/151202a/6.png" alt=""></p>
<p>In order to install the cluster, please see <a href="/2015/12/02b/mapr-on-azure.html">this blog post</a></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>We saw that there are a number of options to install Hadoop on Azure. </p>
<p>Want to comment? I’m sorry, I didn’t leverage a tool like Disqus yet on this blog. Please feel free to e-mail me at my twitter alias at microsoft dot com and I’ll include your remarks in the body of this post. </p>
<p>:-)<br>Benjamin (<a href="http://twitter.com/@benjguin" target="_blank" rel="external">@benjguin</a>) </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.3-4.fr/2015/12/02/different-flavors-of-hadoop/" data-id="ciqaupb9c0003b0cd1jwyxdgu" class="article-share-link">Share</a>
      
        <a href="http://blog.3-4.fr/2015/12/02/different-flavors-of-hadoop/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Azure/">Azure</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Big-Data/">Big Data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/11/27/sqldw-azureml-jupyter-powerbi" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/27/sqldw-azureml-jupyter-powerbi/" class="article-date">
  <time datetime="2015-11-26T23:00:00.000Z" itemprop="datePublished">2015-11-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/27/sqldw-azureml-jupyter-powerbi/">SQL DataWarehouse, Azure Machine Learning, Jupyter, Power BI</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>This blog post shows how to load data from blob storage to the following (in order): </p>
<ul>
<li>SQL Datawarehouse (SQL DW for short). SQL DW has the following advantages<ul>
<li>It can scale up and down in a few seconds</li>
<li>You can load data easily from flat files in Azure Blob with Polybase</li>
<li>SQL is a well known language</li>
<li>You can do joins</li>
<li>You can query it from Azure ML</li>
</ul>
</li>
<li>Azure Machine Learning<ul>
<li>learn from the dataset</li>
<li>tune your model</li>
<li>evaluate scoring and how the model generalize</li>
<li>operationalize as a Web API</li>
</ul>
</li>
<li>a Jupyter notebook<ul>
<li>explore, plot, transform the dataset in Python</li>
<li>document in Markdown</li>
<li>…</li>
</ul>
</li>
<li>Power BI<ul>
<li>visualize your data</li>
<li>Share the dataviz with others</li>
</ul>
</li>
</ul>
<p>There is also a good article with demo videos in the following article: <a href="https://azure.microsoft.com/en-us/blog/using-azure-machine-learning-with-sql-data-warehouse/" target="_blank" rel="external">Using Azure Machine Learning with SQL Data Warehouse</a>.</p>
<h2 id="conventions"><a href="#conventions" class="headerlink" title="conventions"></a>conventions</h2><p>This is a sample.<br>By convention, all values ended by 34 should be replaced by your own values. For instance, the data storage account is <code>mydata34</code>. Yours should have a different name.</p>
<h2 id="the-sample-dataset"><a href="#the-sample-dataset" class="headerlink" title="the sample dataset"></a>the sample dataset</h2><p>The data is available as a number of flat delimited files in a blob storage container. In this example, there are 2 files. here are a few lines of data: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">2012-01-13|02:00:00|W3SVC1273337584|RD00155D360C23|10.211.162.24|GET|/Modules/Orchard.Localization/Styles/orchard-localization-base.css|-|80|-|65.52.74.115|HTTP/1.1|Mozilla/4.0+(compatible;+MSIE+8.0;+Windows+NT+5.1)|__RequestVerificationToken_Lw__=JMngbma7rvbnvrzf3Xos7p8GDz3zu4oNwCqOMd0PpxotKkvlvfzHWsGfYm4BJL5CdOCvg7sdtSdOgRGqG9Uick5Jji4cruyaeOv4fYJeN0snqrkYNUI8M179jbaLw80XvLM2OKk8UjxRpKzwjMbBWt6CilU=|http://site.supersimple.fr/|site.supersimple.fr|304|0|0|209|554|15</div><div class="line">2012-01-13|02:00:00|W3SVC1273337584|RD00155D360C23|10.211.162.24|GET|/|-|80|-|65.52.74.115|HTTP/1.1|Mozilla/4.0+(compatible;+MSIE+8.0;+Windows+NT+5.1)|__RequestVerificationToken_Lw__=JMngbma7rvbnvrzf3Xos7p8GDz3zu4oNwCqOMd0PpxotKkvlvfzHWsGfYm4BJL5CdOCvg7sdtSdOgRGqG9Uick5Jji4cruyaeOv4fYJeN0snqrkYNUI8M179jbaLw80XvLM2OKk8UjxRpKzwjMbBWt6CilU=|-|site.supersimple.fr|200|0|0|1917|367|203</div><div class="line">2012-01-13|02:00:00|W3SVC1273337584|RD00155D360C23|10.211.162.24|GET|/Themes/Classic/Styles/Site.css|-|80|-|65.52.74.115|HTTP/1.1|Mozilla/4.0+(compatible;+MSIE+8.0;+Windows+NT+5.1)|__RequestVerificationToken_Lw__=JMngbma7rvbnvrzf3Xos7p8GDz3zu4oNwCqOMd0PpxotKkvlvfzHWsGfYm4BJL5CdOCvg7sdtSdOgRGqG9Uick5Jji4cruyaeOv4fYJeN0snqrkYNUI8M179jbaLw80XvLM2OKk8UjxRpKzwjMbBWt6CilU=|http://site.supersimple.fr/|site.supersimple.fr|304|0|0|92|520|218</div><div class="line">2012-01-13|02:00:00|W3SVC1273337584|RD00155D360C23|10.211.162.24|GET|/Core/Shapes/scripts/html5.js|-|80|-|65.52.74.115|HTTP/1.1|Mozilla/4.0+(compatible;+MSIE+8.0;+Windows+NT+5.1)|__RequestVerificationToken_Lw__=JMngbma7rvbnvrzf3Xos7p8GDz3zu4oNwCqOMd0PpxotKkvlvfzHWsGfYm4BJL5CdOCvg7sdtSdOgRGqG9Uick5Jji4cruyaeOv4fYJeN0snqrkYNUI8M179jbaLw80XvLM2OKk8UjxRpKzwjMbBWt6CilU=|http://site.supersimple.fr/|site.supersimple.fr|304|0|0|209|517|218</div><div class="line">2012-01-13|02:00:00|W3SVC1273337584|RD00155D360C23|10.211.162.24|GET|/Core/Shapes/scripts/html5.js|-|80|-|65.52.74.115|HTTP/1.1|Mozilla/4.0+(compatible;+MSIE+8.0;+Windows+NT+5.1)|__RequestVerificationToken_Lw__=2aNXfgccF5TrHacVp9ReeLniHeKovLv/1lYP13EyQ4pYy21MvX4WFH+1Kg9/R+02r4vhkZo0wvOLXZ233O0Sn2QC+n+7EobKV6+7J0lqG0F1g/oc/RCSO3NhrWAoFNzqIEUm0AgJkY0MIhA5XPTX0s0jFLw=|http://site.supersimple.fr/|site.supersimple.fr|304|0|0|209|517|265</div><div class="line">2012-01-13|02:00:00|W3SVC1273337584|RD00155D360C23|10.211.162.24|GET|/Core/Shapes/scripts/html5.js|-|80|-|65.52.74.115|HTTP/1.1|Mozilla/4.0+(compatible;+MSIE+8.0;+Windows+NT+5.1)|__RequestVerificationToken_Lw__=JMngbma7rvbnvrzf3Xos7p8GDz3zu4oNwCqOMd0PpxotKkvlvfzHWsGfYm4BJL5CdOCvg7sdtSdOgRGqG9Uick5Jji4cruyaeOv4fYJeN0snqrkYNUI8M179jbaLw80XvLM2OKk8UjxRpKzwjMbBWt6CilU=|http://site.supersimple.fr/|site.supersimple.fr|304|0|0|209|517|218</div></pre></td></tr></table></figure>
<p>Fields are separated by the pipe character (‘|’). The name of the fields are: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">date|time|s-sitename|s-computername|s-ip|cs-method|cs-uri-stem|cs-uri-query|s-port|cs-username|c-ip|cs-version|cs(User-Agent)|cs(Cookie)|cs(Referer)|cs-host|sc-status|sc-substatus|sc-win32-status|sc-bytes|cs-bytes|time-taken</div></pre></td></tr></table></figure>
<p>The data is available in a storage account.<br><img src="/images/151127a/1.png" alt=""></p>
<p>In this example, the storage account name is <code>mydata34</code> and its key is <code>k2JOuW/nru2nW0y3Icpm9yNTYCrUuNSFm9RDyMuBvIKuYqhtPHAK8MW4bVQfWssXp184pGhlKraaOc7sZTDijQ==</code>.</p>
<p>The key can be found in the portal, for example:<br><img src="/images/151127a/2.png" alt=""></p>
<p>NB: by the time your read this page, the key may have change. I share the key so that you can find it in code where it is necessary.</p>
<h2 id="SQL-Datawarehouse-SQL-DW"><a href="#SQL-Datawarehouse-SQL-DW" class="headerlink" title="SQL Datawarehouse (SQL DW)"></a>SQL Datawarehouse (SQL DW)</h2><p>Let’s create a SQL DW. </p>
<p><img src="/images/151127a/3.png" alt=""></p>
<p>choose SQL Data Warehouse and click <code>Create</code>.</p>
<p>Here is the data you can enter: </p>
<ul>
<li>mysqldw34</li>
<li>200 DWU</li>
<li>Create a new Server<ul>
<li>mysqldbsrv34</li>
<li>admin34</li>
<li>DDtgjiuz96<em>__</em></li>
<li>West Europe</li>
</ul>
</li>
</ul>
<p><img src="/images/151127a/4.png" alt=""></p>
<p>Once the SQL DW has been created, we must connect to it. One of the tools you can use is Visual Studio; you can download Visual Studio community edition from <a href="https://www.visualstudio.com/" target="_blank" rel="external">visualstudio.com</a>. Please refer to <a href="https://azure.microsoft.com/en-us/documentation/articles/sql-data-warehouse-get-started-connect/" target="_blank" rel="external">Connect to SQL Data Warehouse with Visual Studio</a> for details.</p>
<p>You must allow your own IP address to access the SQL DB server: </p>
<p><img src="/images/151127a/5.png" alt=""></p>
<p>Let’s load the data.<br>Here is the code that you can paste in Visual Studio and execute:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">--also refer to https://azure.microsoft.com/en-us/documentation/articles/sql-data-warehouse-load-with-polybase/</div><div class="line"></div><div class="line"></div><div class="line">-- Create a master key</div><div class="line">CREATE MASTER KEY;</div><div class="line"></div><div class="line">CREATE DATABASE SCOPED CREDENTIAL mydata_secret </div><div class="line">	WITH IDENTITY = &apos;dummy&apos;, </div><div class="line">	Secret = &apos;k2JOuW/nru2nW0y3Icpm9yNTYCrUuNSFm9RDyMuBvIKuYqhtPHAK8MW4bVQfWssXp184pGhlKraaOc7sZTDijQ==&apos;;</div><div class="line"></div><div class="line">SELECT * FROM sys.database_credentials;</div><div class="line"></div><div class="line">CREATE EXTERNAL DATA SOURCE mydata_datasource WITH</div><div class="line">(</div><div class="line">	TYPE=Hadoop, </div><div class="line">	LOCATION=&apos;wasbs://container1@mydata34.blob.core.windows.net&apos;, </div><div class="line">	CREDENTIAL=mydata_secret</div><div class="line">);</div><div class="line"></div><div class="line">CREATE EXTERNAL FILE FORMAT PIPE_fileformat WITH (</div><div class="line">	FORMAT_TYPE = DELIMITEDTEXT,</div><div class="line">	FORMAT_OPTIONS (</div><div class="line">		FIELD_TERMINATOR=&apos;|&apos;)</div><div class="line">);</div><div class="line"></div><div class="line">drop external table mydata_externaltable;</div><div class="line">create external table mydata_externaltable</div><div class="line">(</div><div class="line">	[date] varchar(255), </div><div class="line">	[time] varchar(255), </div><div class="line">	[s-sitename] varchar(255), </div><div class="line">	[s-computername] varchar(255), </div><div class="line">	[s-ip] varchar(255), </div><div class="line">	[cs-method] varchar(255), </div><div class="line">	[cs-uri-stem] varchar(255), </div><div class="line">	[cs-uri-query] varchar(4000), </div><div class="line">	[s-port] varchar(255), </div><div class="line">	[cs-username] varchar(255), </div><div class="line">	[c-ip] varchar(255), </div><div class="line">	[cs-version] varchar(255), </div><div class="line">	[cs(User-Agent)] varchar(255), </div><div class="line">	[cs(Cookie)] varchar(4000), </div><div class="line">	[cs(Referer)] varchar(255), </div><div class="line">	[cs-host] varchar(255), </div><div class="line">	[sc-status] varchar(255), </div><div class="line">	[sc-substatus] varchar(255), </div><div class="line">	[sc-win32-status] varchar(255), </div><div class="line">	[sc-bytes] varchar(255), </div><div class="line">	[cs-bytes] varchar(255), </div><div class="line">	[time-taken] varchar(255)</div><div class="line">)</div><div class="line">WITH (</div><div class="line">	LOCATION=&apos;/flat_files&apos;,</div><div class="line">	DATA_SOURCE = mydata_datasource,</div><div class="line">	FILE_FORMAT = PIPE_fileformat,</div><div class="line">	REJECT_TYPE = percentage,</div><div class="line">	REJECT_VALUE = 90,</div><div class="line">	REJECT_SAMPLE_VALUE = 200</div><div class="line">);</div><div class="line"></div><div class="line"></div><div class="line">-- create table as select: https://azure.microsoft.com/en-us/documentation/articles/sql-data-warehouse-develop-ctas/</div><div class="line">CREATE TABLE [dbo].[mydata]</div><div class="line">WITH</div><div class="line">(</div><div class="line">    DISTRIBUTION = ROUND_ROBIN,</div><div class="line">    CLUSTERED COLUMNSTORE INDEX</div><div class="line">)</div><div class="line">AS</div><div class="line">	SELECT * FROM mydata_externaltable;</div></pre></td></tr></table></figure>
<p>the result of the last statement is</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">    (44819 row(s) affected)</div><div class="line">    </div><div class="line">Query completed. Rows were rejected while reading from external source(s). </div><div class="line">4 rows rejected from external table [mydata_externaltable] in plan step 5 of query execution:</div><div class="line">	Location: &apos;/flat_files/weblogs1.txt&apos; Column ordinal: 6, Expected data type: VARCHAR(255) collate SQL_Latin1_General_CP1_CI_AS, Offending value: #Software:|Microsoft|Internet|Information|Services|7.5 (Tokenization failed), Error: Not enough columns in this line.</div><div class="line">	Location: &apos;/flat_files/weblogs1.txt&apos; Column ordinal: 2, Expected data type: VARCHAR(255) collate SQL_Latin1_General_CP1_CI_AS, Offending value: #Version:|1.0 (Tokenization failed), Error: Not enough columns in this line.</div><div class="line">	Location: &apos;/flat_files/weblogs1.txt&apos; Column ordinal: 3, Expected data type: VARCHAR(255) collate SQL_Latin1_General_CP1_CI_AS, Offending value: #Date:|2012-01-13|01:59:59 (Tokenization failed), Error: Not enough columns in this line.</div><div class="line">	Location: &apos;/flat_files/weblogs1.txt&apos; Column ordinal: 21, Expected data type: VARCHAR(255) collate SQL_Latin1_General_CP1_CI_AS, Offending value: |time-taken (Tokenization failed), Error: Too many columns in the line.</div></pre></td></tr></table></figure>
<p>each file has ~22000 lines so the total numlber of lines seems good.</p>
<p>The rejected lines are some headers that are inside regular rows: </p>
<p><img src="/images/151127a/6.png" alt=""> </p>
<p>We can now query the data: </p>
<p><img src="/images/151127a/7.png" alt=""> </p>
<h2 id="Azure-Machine-Learning"><a href="#Azure-Machine-Learning" class="headerlink" title="Azure Machine Learning"></a>Azure Machine Learning</h2><p>Let’s now get a subset of the data in Azure Machine Learning.<br>For example, the query we need is </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select top 1500 * from mydata WHERE [sc-status]=&apos;200&apos; ORDER BY date, time asc</div></pre></td></tr></table></figure>
<p>Let’s assume you have an Azure Machine learning available. You’ve created a new experiment from the Studio at <a href="https://studio.azureml.net" target="_blank" rel="external">studio.azureml.net</a>.</p>
<p>Then add a reader</p>
<p><img src="/images/151127a/8.png" alt=""> </p>
<p>In the properties, choose and fill: </p>
<ul>
<li>Azure SQL Database</li>
<li>mysqldbsrv34.database.windows.net</li>
<li>mysqldw34</li>
<li>admin34</li>
<li>DDtgjiuz96<em>__</em></li>
<li>select top 1500 * from mydata WHERE [sc-status]=’200’ ORDER BY date, time asc</li>
</ul>
<p><img src="/images/151127a/9.png" alt=""> </p>
<p>click Run at the bottom of the page, then you can visualize the dataset</p>
<p><img src="/images/151127a/11.png" alt=""></p>
<p><img src="/images/151127a/10.png" alt=""></p>
<h2 id="Jupyter"><a href="#Jupyter" class="headerlink" title="Jupyter"></a>Jupyter</h2><p>You may also want to use the dataset in a Jupyter notebook.<br>For that, you just have to convert the dataset to CSV and then generate the code to access the dataset from Azure Machine Learning.</p>
<p>Drag &amp; drop the Convert to CSV shape, connect it to the reader. Then you can generate the Python code to access that dataset or directly ask for a new notebook that will have access to the dataset: </p>
<p><img src="/images/151127a/12.png" alt=""></p>
<p><img src="/images/151127a/13.png" alt=""></p>
<h2 id="PowerBI"><a href="#PowerBI" class="headerlink" title="PowerBI"></a>PowerBI</h2><p>You may also want to see your dataset</p>
<p>For that, you can go to your Power BI environment at <a href="https://app.powerbi.com" target="_blank" rel="external">app.powerbi.com</a>, choose Get Data, Databases &amp; More and choose Azure SQL Data Warehouse.</p>
<p><img src="/images/151127a/14.png" alt=""></p>
<ul>
<li>mysqldbsrv34.database.windows.net</li>
<li>mysqldw34</li>
<li>Next</li>
<li>admin34</li>
<li>DDtgjiuz96<em>__</em></li>
</ul>
<p>from there, you have the dataset available, and can visualize it: </p>
<p><img src="/images/151127a/15.png" alt=""></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>We saw how to load flat files in a SQL DW, then in Azure Machine Learning and Jupyter, as well as Power BI.</p>
<p>:-) <a href="https://twitter.com/benjguin" target="_blank" rel="external">benjguin</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.3-4.fr/2015/11/27/sqldw-azureml-jupyter-powerbi/" data-id="ciq9yp26f0001p0cdcbdd6ypd" class="article-share-link">Share</a>
      
        <a href="http://blog.3-4.fr/2015/11/27/sqldw-azureml-jupyter-powerbi/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Azure/">Azure</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Big-Data/">Big Data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Data-Science/">Data Science</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-2015/11/20/une-vm-datascience-dans-azure" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/20/une-vm-datascience-dans-azure/" class="article-date">
  <time datetime="2015-11-19T23:00:00.000Z" itemprop="datePublished">2015-11-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/20/une-vm-datascience-dans-azure/">Une Machine Virtuelle Dans Azure Avec Des Outils De Data Science</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Une-machine-virtuelle-dans-Azure-avec-des-outils-de-data-science"><a href="#Une-machine-virtuelle-dans-Azure-avec-des-outils-de-data-science" class="headerlink" title="Une machine virtuelle dans Azure avec des outils de data science"></a>Une machine virtuelle dans Azure avec des outils de data science</h2><p>Microsoft a <a href="https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=MachineLearning&amp;announcementId=7edd436b-93e2-4e61-84fb-ba3966d4092d" target="_blank" rel="external">mis à disposition récemment</a> un modèle de machine virtuelle avec un ensemble d’outils utiles en data science. On peut créer cette machine virtuelle depuis la marketplace Azure. Il existe d’autres VM sur le même thème, comme vous pouvez le voir en allant à <a href="https://azure.microsoft.com/en-us/marketplace/?term=data+science" target="_blank" rel="external">https://azure.microsoft.com/en-us/marketplace/?term=data+science</a>:</p>
<p><img src="/images/151120a/1.png" alt=""></p>
<p>Penchons-nous plus spécifiquement sur la machine virtuelle “Standard Data Science VM” de Microsoft. Elle comprend les outils suivants:<br>Revolution R Open, une distribution Anaconda Python incluant Jupyter notebook server, Visual Studio Community Edition, Power BI Desktop, SQL Server Express edition et le SDK Azure.</p>
<p>Pour créer votre propre VM à partir de ce modèle, voici comment procéder. </p>
<p>Depuis la <a href="https://azure.microsoft.com/en-us/marketplace/partners/microsoft-ads/standard-data-science-vm/" target="_blank" rel="external">page de présentation de la VM</a>, il vous suffit de cliquer sur le bouton “Create Virtual Machine&gt;”, ce qui vous amène dans <a href="https://portal.azure.com/#create/microsoft-ads.standard-data-science-vmstandard-data-science-vm" target="_blank" rel="external">la page de création dans le portail</a>.</p>
<p>NB: Depuis le portail, on peut aussi chercher cette VM:<br><img src="/images/151120a/2.png" alt=""></p>
<p>On arrive donc sur cette page de description qui permet de créer la machine virtuelle:<br><img src="/images/151120a/3.png" alt=""></p>
<p>Vous remplissez ensuite les différentes rubriques.<br><img src="/images/151120a/4.png" alt=""></p>
<p>Voici quelques éléments notables: </p>
<ul>
<li>Basics<ul>
<li>Vous ne pouvez mettre qu’un mot de passe, pas de clef SSH, car la VM est sous Windows et que Windows ne supporte pas encore SSH. </li>
<li>Location: Si vous travaillez depuis la France, je vous recommande North Europe ou West Europe.</li>
</ul>
</li>
<li>Size<ul>
<li>Quelques tailles recommandées sont proposées. Regardez aussi “View All” pour voir s’il n’y a pas des rapports qualité/prix qui vous intéressent plus.  </li>
</ul>
</li>
<li>Settings: <ul>
<li>Storage account. Pour les utilisateurs habituels d’Azure, si vous avez déjà des comptes de stockage, seuls ceux qui apparaissent dans la rubrique “storage account” peuvent être utilisés ici. Ceux dans la rubrique “storage accounts (classic)” ne sont pas utilisables pour héberger le disque VHD de cette VM que vous créez en mode “Resource Manager”. Voir par exemple <a href="https://channel9.msdn.com/Events/Build/2015/3-618" target="_blank" rel="external">cette session</a> pour plus de détails.</li>
<li>vous pouvez garder les options par défaut des autres rubriques de cette section</li>
</ul>
</li>
</ul>
<p>Quand la machine virtuelle a été créée, vous pouvez vous y connecter en cliquant sur le lien suivant dans le portail:</p>
<p><img src="/images/151120a/5.png" alt=""></p>
<p>Cela télécharge un fichier .rdp (rdp=remote desktop protocol) que vous pouvez ouvrir ou conserver pour les prochaines connexions.</p>
<p>Vous pouvez ignorer ce genre de warning<br><img src="/images/151120a/6.png" alt=""><br>et cliquer sur Connect.</p>
<p>Vous vous connectez avec le compte et le mot de passe que vous avez définis lors de la création de la machine virtuelle.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://blog.3-4.fr/2015/11/20/une-vm-datascience-dans-azure/" data-id="ciqaupb9c0001b0cdxt1djyah" class="article-share-link">Share</a>
      
        <a href="http://blog.3-4.fr/2015/11/20/une-vm-datascience-dans-azure/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Azure/">Azure</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Data-Science/">Data Science</a></li></ul>

    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Azure/">Azure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Big-Data/">Big Data</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Science/">Data Science</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Azure/" style="font-size: 20px;">Azure</a> <a href="/tags/Big-Data/" style="font-size: 16.67px;">Big Data</a> <a href="/tags/Data-Science/" style="font-size: 13.33px;">Data Science</a> <a href="/tags/Hadoop/" style="font-size: 13.33px;">Hadoop</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/12/02/mapr-on-azure/">MapR on Azure</a>
          </li>
        
          <li>
            <a href="/2015/12/02/different-flavors-of-hadoop/">Different Flavors of Hadoop &amp; Spark</a>
          </li>
        
          <li>
            <a href="/2015/11/27/sqldw-azureml-jupyter-powerbi/">SQL DataWarehouse, Azure Machine Learning, Jupyter, Power BI</a>
          </li>
        
          <li>
            <a href="/2015/11/20/une-vm-datascience-dans-azure/">Une Machine Virtuelle Dans Azure Avec Des Outils De Data Science</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Benjamin Guinebertière<br>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'benjguin-blog34';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>